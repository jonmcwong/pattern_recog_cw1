{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.io\n",
    "import numpy as np\n",
    "from numpy import linalg as LA\n",
    "import matplotlib\n",
    "import time\n",
    "from PIL import Image\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from functions import *\n",
    "from numpy import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data\n",
    "mat = scipy.io.loadmat('face.mat')\n",
    "raw_data = mat['X']\n",
    "\n",
    "D,N = raw_data.shape\n",
    "\n",
    "raw_data = np.transpose(raw_data)\n",
    "\n",
    "partitioned_training_data = np.empty([4,int(520*0.8), 2576])\n",
    "\n",
    "testing_data = np.empty([int(520*0.2), 2576])\n",
    "\n",
    "# create training and test data\n",
    "for x in range(52):\n",
    "    for y in range(4):\n",
    "        partitioned_training_data[y][x*2:(x+1)*2] = raw_data[x*10+(2*y):x*10+(2*(y+1))]\n",
    "    testing_data[x*2:(x+1)*2] = raw_data[x*10+8:(x+1)*10]\n",
    "    \n",
    "\n",
    "raw_data = np.transpose(raw_data)\n",
    "training_data = np.transpose(partitioned_training_data)\n",
    "testing_data = np.transpose(testing_data)\n",
    "\n",
    "mean = np.empty([4,2576])\n",
    "\n",
    "for i in range(4):\n",
    "    mean[i] = partitioned_training_data[i].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute covariance matrix and mean of dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "S = np.empty([4,416,416])\n",
    "D = np.empty([4])\n",
    "N = np.empty([4])\n",
    "A = np.empty([4,416,2576])\n",
    "\n",
    "for i in range(4):\n",
    "    A[i] = partitioned_training_data[i] - mean[i]\n",
    "    D[i],N[i] = A[i].shape\n",
    "    S[i] = (1/N[i])*np.dot(A[i],A[i].T) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using only 1 partition of the training dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Combine partition 0 and 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "new cov shape:  (416, 416)\n"
     ]
    }
   ],
   "source": [
    "# new_mu = (N[0]*mean[0] + N[1]*mean[1])/(N[0]+N[1])\n",
    "# new_cov = (N[0]/(N[0]+N[1]))*S[0] + (N[1]/(N[0]+N[1]))*S[1] + ((N[0]*N[1])/(N[0]+N[1])**2)*np.dot(mean[0]-mean[1],(mean[0]-mean[1]).T)\n",
    "new_mu = combined_mean(N,mean,0,1)\n",
    "new_cov = combined_cov(N,S,mean,0,1)\n",
    "\n",
    "q,r = LA.qr(new_cov)\n",
    "\n",
    "p = np.matmul(q,r)\n",
    "w,v = LA.eig(new_cov)\n",
    "\n",
    "u = np.matmul(A[0].T,v)\n",
    "\n",
    "u /= LA.norm(u,ord=2,axis=0)\n",
    "id = np.argsort(np.abs(w))[::-1]\n",
    "w = w[id]\n",
    "u = u[:,id].real\n",
    "show_img(u[:,0])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2576, 104)\n"
     ]
    }
   ],
   "source": [
    "input = testing_data\n",
    "print(testing_data.shape)\n",
    "mean_face = new_mu.reshape(-1,1)\n",
    "eigenface = u\n",
    "n = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "faces = reconstruct(input, mean_face, eigenface, n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[192.82026403 190.86398007 185.18327846 ... 145.52666503 140.66404053\n",
      "  175.85113315]\n",
      " [170.00844808 163.68638554 157.97457332 ... 154.18868991 154.42767895\n",
      "  189.04272177]\n",
      " [217.01745086 220.85000927 237.4060511  ...  28.33020096   2.85684117\n",
      "    9.76840287]\n",
      " ...\n",
      " [152.2064263  142.92543301 143.87142138 ... 289.34643327 267.7691117\n",
      "  281.26726631]\n",
      " [199.52182393 202.34543541 215.77551548 ... 162.89768527 142.81498088\n",
      "  166.4975354 ]\n",
      " [185.3388485  178.35362738 169.07434555 ... 168.39147289 134.1242003\n",
      "  149.87231614]]\n"
     ]
    }
   ],
   "source": [
    "print(faces)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(6):\n",
    "    show_img(faces[i,:])\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Perform Incremental PCA, and compare it with the counterpart i.e. :\n",
    "    - batch PCA\n",
    "    - PCA trained only by the first subset\n",
    "    \n",
    "in terms of :\n",
    "    - training time\n",
    "    - reconstruction error\n",
    "    - face recognition accuracy.\n",
    "    \n",
    "Show and discuss, including: how accurate your incremental method is, what important\n",
    "parameters in the method are (and how they are set). Provide your own discussions and\n",
    "measurements to support. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
