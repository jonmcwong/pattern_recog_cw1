{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "import scipy.io\n",
    "import numpy as np               # for arrays\n",
    "from numpy import linalg as LA   # for eigenvalues\n",
    "import matplotlib                # for plots\n",
    "import time                      # for time measurements\n",
    "from PIL import Image            # for showing images\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import preprocessing\n",
    "import sympy\n",
    "from functions import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_img(img):\n",
    "    temp = img.copy()\n",
    "    temp.resize((46,56))\n",
    "    im = Image.fromarray(temp.T)\n",
    "    im.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get training/test splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data\n",
    "mat = scipy.io.loadmat('face.mat')\n",
    "raw_data = mat['X']\n",
    "\n",
    "raw_data = np.transpose(raw_data)\n",
    "N,D = raw_data.shape\n",
    "C = 52 # number of classes in dataset\n",
    "train_size = int(N * 0.8)\n",
    "test_size = int(N * 0.2)\n",
    "\n",
    "pca_training_data = np.empty([int(520*0.8), 2576])\n",
    "pca_testing_data = np.empty([int(520*0.2), 2576])\n",
    "lda_training_data = []\n",
    "lda_testing_data = []\n",
    "\n",
    "# create training and test data\n",
    "for x in range(52):\n",
    "    # 8/2 ratio for training and testing datasets\n",
    "    lda_training_data.append(raw_data[x*10:x*10+8].copy())\n",
    "    lda_testing_data.append(raw_data[x*10+8:(x+1)*10].copy())\n",
    "    \n",
    "\n",
    "lda_training_data = np.array(lda_training_data)\n",
    "lda_testing_data = np.array(lda_testing_data)\n",
    "# pca_training_data = lda_training_data.reshape(train_size, D)\n",
    "# pca_testing_data = lda_testing_data.reshape(test_size,D)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data\n",
    "mat = scipy.io.loadmat('face.mat')\n",
    "raw_data = mat['X']\n",
    "\n",
    "D,N = raw_data.shape\n",
    "\n",
    "raw_data = np.transpose(raw_data)\n",
    "\n",
    "training_data = np.empty([int(520*0.8), 2576])\n",
    "testing_data = np.empty([int(520*0.2), 2576])\n",
    "\n",
    "# create training and test data\n",
    "for x in range(52):\n",
    "    training_data[x*8:(x+1)*8] = raw_data[x*10:x*10+8]\n",
    "    testing_data[x*2:(x+1)*2] = raw_data[x*10+8:(x+1)*10]\n",
    "\n",
    "raw_data = np.transpose(raw_data)\n",
    "pca_training_data = np.transpose(training_data).T\n",
    "pca_testing_data = np.transpose(testing_data).T\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to make sure that the generalised eigenvalue problem that we encounter when doing LDA is solvable by making sure that the within-class scatter matrix is non-singular.\n",
    "We do this by first reducing the dimension of the data via low dim PCA to an M <= N - c."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_Wpca(data, out_dim,random, M0, M1):\n",
    "    # low-dim PCA\n",
    "    S = data.dot(data.T)\n",
    "    w, v = LA.eigh(S)\n",
    "    u = data.T.dot(v)\n",
    "    u = u.T # the eigenvectors aren't normalised after this\n",
    "    u /= LA.norm(u, ord=2, axis=0)\n",
    "    \n",
    "    # sort wrt abs(eigenvalue)\n",
    "    id = np.argsort(np.abs(w))[::-1]\n",
    "    w = w[id]\n",
    "    u = u[id]\n",
    "    if random == True:\n",
    "        origin = u[:M0].copy()\n",
    "        remaining = u[M0:].copy()\n",
    "        random_features = remaining[np.random.choice(remaining.shape[0], M1, replace=False), :]\n",
    "        new_u = np.concatenate((origin,random_features), axis=0)\n",
    "        print(new_u.T)\n",
    "        return new_u.T\n",
    "        \n",
    "        \n",
    "    else:\n",
    "        print(u[0:out_dim].T.shape)\n",
    "        return u[0:out_dim].T\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# yo = get_Wpca(pca_training_data, 400, True, 50, 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We want a projection that maximises the ratio between the between-class scatter matrix and the within class scatter matrix.\n",
    "The projection W turns out to be the solutions to the generalised eigen value problem. (Found via solving the langrangian. Slide 10-11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_Wlda(Sb_data, Sw_data, out_dim):\n",
    "    #code that gets value\n",
    "    lda_evals, lda_evecs = LA.eig(LA.inv(Sw_data).dot(Sb_data))\n",
    "    # print(\"magnitud of eigenvecs: \", LA.norm(lda_evecs.T[0], ord=2, axis=0))\n",
    "    lda_evecs = lda_evecs.T\n",
    "#     print(\"lda_evals: \", lda_evals)\n",
    "    \n",
    "    # sort wrt abs(eigenvalue)\n",
    "    id = np.argsort(np.abs(lda_evals))[::-1]\n",
    "    lda_evals = lda_evals[id]\n",
    "    lda_evecs = lda_evecs[id]\n",
    "    return lda_evecs[0:out_dim].T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_Wopt(pca_data, lda_data, Mpca, Mlda, random=False, M0=40, M1=10, committee_size=2):\n",
    "    # random is true, returns tensor of random Wopts\n",
    "    mean_all_data = pca_data.T.mean(axis=1).T\n",
    "\n",
    "    # between class scatter (scalar)\n",
    "    mean_class_data = lda_data.mean(axis=1)\n",
    "    diff_class_mean = mean_class_data - mean_all_data\n",
    "    Sb = np.dot(diff_class_mean.T, diff_class_mean)\n",
    "    Sb *= np.array([8])\n",
    "\n",
    "    # within class scatter (scalar)\n",
    "    diff_class_data = lda_data - mean_class_data.reshape(52,1,-1)\n",
    "    Sw = np.zeros((2576, 2576));\n",
    "    for x in diff_class_data:\n",
    "        Sw += np.dot(x.T,x)\n",
    "    #use\n",
    "    new_ensemble = np.empty([committee_size, 2576, M0 + M1])\n",
    "    for x in range(committee_size):\n",
    "        print(x)\n",
    "        Wpca = get_Wpca(pca_data, Mpca, True, M0, M1)\n",
    "        reduced_Sb = Wpca.T.dot(Sb).dot(Wpca) # symmetric matrix hopefully\n",
    "        reduced_Sw = Wpca.T.dot(Sw).dot(Wpca)\n",
    "        Wlda = get_Wlda(reduced_Sb, reduced_Sw, Mlda)\n",
    "\n",
    "        Wopt = Wlda.T.dot(Wpca.T).T\n",
    "        Wopt /= LA.norm(Wopt, ord=2, axis=1, keepdims=True)\n",
    "        new_ensemble[x] = Wopt\n",
    "        \n",
    "#     print(\"Wopt: \", Wopt.shape, \" Wlda.T: \", Wlda.T.shape, \" Wpca.T \", Wpca.T.shape)\n",
    "    \n",
    "    return new_ensemble"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now express each data point as product of a weight vector with Wopt. This weight vector can be used to classify each data point using nearest neighbour"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_PCALDA_accuracy(Mpca, Mlda,random=False, M0=46, M1=1, committee_size=10):\n",
    "    \n",
    "    W = get_Wopt(pca_training_data, lda_training_data, Mpca, Mlda, random, M0, M1, committee_size)\n",
    "#     print(\"reached here\")\n",
    "    \n",
    "    training_face_weights = np.matmul(np.transpose(W,(0,2,1)),pca_training_data.T)\n",
    "    testing_face_weights = np.matmul(np.transpose(W,(0,2,1)),pca_testing_data.T)\n",
    "#     print(\"training_face_weights.shape\", training_face_weights.shape)\n",
    "#     print(\"tresting_face_weights.shape\", testing_face_weights.shape)\n",
    "    \n",
    "    result = class_rate_tensor(np.transpose(training_face_weights.real,(0,2,1)), np.transpose(testing_face_weights.real, (0,2,1)))\n",
    "    acc = 100*np.sum(result, axis=-1)/len(result)\n",
    "    print(\"Mpca: \", Mpca, \" Mlda: \", Mlda, \" Classification rate: \", acc, \"%.\")\n",
    "    return acc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'percent' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-57d8a98ba917>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# percent = get_PCALDA_accuracy(46,12)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpercent\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'percent' is not defined"
     ]
    }
   ],
   "source": [
    "# percent = get_PCALDA_accuracy(46,12)\n",
    "print(percent)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now lets test the accuracy of the classifier as we vary Mpca from 1 to 416 and keeping LDA at 416. \n",
    "When the dimensions D is larger than the number of data points, the within-class covariance matrix becomes singular and so cannot be inverted. Therefore, PCA is used on the data before LDA in order to reduce the dimensions of the data and make Sw non-singular.\n",
    "\n",
    "Another reason is that having an Mpca too high is known to make the model overfit. This is because when the dimension of data is much larger than the number of data points, finding a linear projection into a lower dimension that separates the classes completely becomes very easy and the projection found often does not generalise well. In this light, PCA can be seen as a regularisation technique.\n",
    "\n",
    "https://stats.stackexchange.com/questions/106121/does-it-make-sense-to-combine-pca-and-lda\n",
    "\n",
    "For this dataset, the best regularisation is Mpca = 46"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# results = []\n",
    "# for i in range(1, 417):\n",
    "#     results.append(get_PCALDA_accuracy(i, 417))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "results = np.loadtxt(\"VaryingPca.txt\")\n",
    "plot_data(\"Nearest Neigbhour Classification accuracy against Mpca\", \"Mpca\", \"Classification accuracy %\", results)\n",
    "# plt.savefig(\"Vary_Mpca_NN.png\")\n",
    "# np.savetxt(\"VaryingPca.txt\", results)\n",
    "# this graph shows that the test accuracy initially increases as Mpca increases as the model is given more \n",
    "# information to work with. Maximum accuracy is reached when Mpca is at 46. When Mpca increases above 46, \n",
    "# the model overfits and test accuracy decreases. This problem can be solved by using more data samples.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ldaresults = []\n",
    "# for i in range(1, 417):\n",
    "#     ldaresults.append(get_PCALDA_accuracy(47, i))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ldaresults = np.loadtxt(\"VaryingLda.txt\")\n",
    "ldaresults2 = ldaresults[0:47]\n",
    "plot_data(\"Nearest Neighbour Classification accuracy against Mlda 2\",\"Mlda\",\"Classification accuracy\", ldaresults2)\n",
    "# np.savetxt(\"VaryingLda.txt\", ldaresults)\n",
    "# this graph shows that only the first 50 largest eigenvalues from LDA give discriminate between the different classes\n",
    "# the smallest eigenvalues are too small or zero"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ensembles aim to create stronger classifiers by fusing the predictions of multiple weaker classifiers in the hope that their individual strengths cover different areas of the input space or that the weak experts reinforce each others decisions. The weak classifiers in an ensemble can be created by either randomly sampling in feature space or by training on random subsets of the data set. There output is then fused by a fusion rule, the type of fusion rule chosen affects that overall performance of the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First do pca, then do LDA on a random subset of those principal components\n",
    "get their individual classifications \n",
    "get their combined classification using some fusion rule - READ UP\n",
    "start decimating models randomly, down to 1 model to see how the number of models affects output score\n",
    "\n",
    "Get random samples of data sets create samples randomly and then classify each data set in series\n",
    "keep their models and run them individually on the whole dataset\n",
    "combine their outputs using some fusion rule\n",
    "decimate models randomly like above\n",
    "\n",
    "try different fusion rules for each different model number\n",
    "\n",
    "the effect of different fusion rules on a committee machines composed of varying number of weaker machines\n",
    "\n",
    "Vary randomness parametre\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "[[ 9.28306007e-01 -9.00656771e-02  4.37697997e-02 ...  2.41188421e-04\n",
      "  -8.05277781e-03  8.32465982e-03]\n",
      " [ 9.29676296e-01 -9.67442415e-02  5.06287832e-02 ... -1.55347660e-02\n",
      "  -1.09861577e-02  1.10953665e-03]\n",
      " [ 9.28088228e-01 -1.02934185e-01  5.98288545e-02 ... -2.60653446e-02\n",
      "  -2.25315897e-02 -6.06860182e-03]\n",
      " ...\n",
      " [ 8.42166732e-01  3.09011440e-01  1.90171066e-01 ... -3.49012074e-02\n",
      "   3.68743710e-03  3.01558984e-03]\n",
      " [ 8.36926421e-01  3.09991095e-01  1.88881687e-01 ... -4.97899055e-02\n",
      "   2.50082387e-03 -4.66022454e-03]\n",
      " [ 8.30329750e-01  3.18890266e-01  1.83496822e-01 ... -4.80590157e-02\n",
      "  -7.60365360e-03 -1.14630536e-02]]\n",
      "1\n",
      "[[ 9.28306007e-01 -9.00656771e-02  4.37697997e-02 ...  2.41188421e-04\n",
      "  -8.05277781e-03 -4.19176292e-03]\n",
      " [ 9.29676296e-01 -9.67442415e-02  5.06287832e-02 ... -1.55347660e-02\n",
      "  -1.09861577e-02 -1.65961794e-04]\n",
      " [ 9.28088228e-01 -1.02934185e-01  5.98288545e-02 ... -2.60653446e-02\n",
      "  -2.25315897e-02 -3.83589869e-03]\n",
      " ...\n",
      " [ 8.42166732e-01  3.09011440e-01  1.90171066e-01 ... -3.49012074e-02\n",
      "   3.68743710e-03 -5.80193686e-03]\n",
      " [ 8.36926421e-01  3.09991095e-01  1.88881687e-01 ... -4.97899055e-02\n",
      "   2.50082387e-03 -7.75322777e-03]\n",
      " [ 8.30329750e-01  3.18890266e-01  1.83496822e-01 ... -4.80590157e-02\n",
      "  -7.60365360e-03  3.29638139e-03]]\n",
      "2\n",
      "[[ 9.28306007e-01 -9.00656771e-02  4.37697997e-02 ...  2.41188421e-04\n",
      "  -8.05277781e-03 -1.37819932e-03]\n",
      " [ 9.29676296e-01 -9.67442415e-02  5.06287832e-02 ... -1.55347660e-02\n",
      "  -1.09861577e-02  1.25022195e-03]\n",
      " [ 9.28088228e-01 -1.02934185e-01  5.98288545e-02 ... -2.60653446e-02\n",
      "  -2.25315897e-02  2.21813923e-03]\n",
      " ...\n",
      " [ 8.42166732e-01  3.09011440e-01  1.90171066e-01 ... -3.49012074e-02\n",
      "   3.68743710e-03  1.03497811e-03]\n",
      " [ 8.36926421e-01  3.09991095e-01  1.88881687e-01 ... -4.97899055e-02\n",
      "   2.50082387e-03  1.64218954e-03]\n",
      " [ 8.30329750e-01  3.18890266e-01  1.83496822e-01 ... -4.80590157e-02\n",
      "  -7.60365360e-03  2.35028410e-03]]\n",
      "3\n",
      "[[ 9.28306007e-01 -9.00656771e-02  4.37697997e-02 ...  2.41188421e-04\n",
      "  -8.05277781e-03 -1.18940439e-03]\n",
      " [ 9.29676296e-01 -9.67442415e-02  5.06287832e-02 ... -1.55347660e-02\n",
      "  -1.09861577e-02  1.86968607e-03]\n",
      " [ 9.28088228e-01 -1.02934185e-01  5.98288545e-02 ... -2.60653446e-02\n",
      "  -2.25315897e-02  1.19989788e-03]\n",
      " ...\n",
      " [ 8.42166732e-01  3.09011440e-01  1.90171066e-01 ... -3.49012074e-02\n",
      "   3.68743710e-03  6.63745724e-04]\n",
      " [ 8.36926421e-01  3.09991095e-01  1.88881687e-01 ... -4.97899055e-02\n",
      "   2.50082387e-03  1.41262389e-03]\n",
      " [ 8.30329750e-01  3.18890266e-01  1.83496822e-01 ... -4.80590157e-02\n",
      "  -7.60365360e-03 -3.06645640e-04]]\n",
      "4\n",
      "[[ 9.28306007e-01 -9.00656771e-02  4.37697997e-02 ...  2.41188421e-04\n",
      "  -8.05277781e-03  1.67725896e-03]\n",
      " [ 9.29676296e-01 -9.67442415e-02  5.06287832e-02 ... -1.55347660e-02\n",
      "  -1.09861577e-02  8.98224878e-04]\n",
      " [ 9.28088228e-01 -1.02934185e-01  5.98288545e-02 ... -2.60653446e-02\n",
      "  -2.25315897e-02  4.91618354e-04]\n",
      " ...\n",
      " [ 8.42166732e-01  3.09011440e-01  1.90171066e-01 ... -3.49012074e-02\n",
      "   3.68743710e-03  2.40530268e-03]\n",
      " [ 8.36926421e-01  3.09991095e-01  1.88881687e-01 ... -4.97899055e-02\n",
      "   2.50082387e-03 -2.75842902e-03]\n",
      " [ 8.30329750e-01  3.18890266e-01  1.83496822e-01 ... -4.80590157e-02\n",
      "  -7.60365360e-03 -1.16292452e-03]]\n",
      "5\n",
      "[[ 9.28306007e-01 -9.00656771e-02  4.37697997e-02 ...  2.41188421e-04\n",
      "  -8.05277781e-03  1.23957735e-02]\n",
      " [ 9.29676296e-01 -9.67442415e-02  5.06287832e-02 ... -1.55347660e-02\n",
      "  -1.09861577e-02  3.38658625e-03]\n",
      " [ 9.28088228e-01 -1.02934185e-01  5.98288545e-02 ... -2.60653446e-02\n",
      "  -2.25315897e-02 -8.54511564e-03]\n",
      " ...\n",
      " [ 8.42166732e-01  3.09011440e-01  1.90171066e-01 ... -3.49012074e-02\n",
      "   3.68743710e-03  2.37316367e-02]\n",
      " [ 8.36926421e-01  3.09991095e-01  1.88881687e-01 ... -4.97899055e-02\n",
      "   2.50082387e-03  1.56053341e-02]\n",
      " [ 8.30329750e-01  3.18890266e-01  1.83496822e-01 ... -4.80590157e-02\n",
      "  -7.60365360e-03  6.59592329e-03]]\n",
      "6\n",
      "[[ 9.28306007e-01 -9.00656771e-02  4.37697997e-02 ...  2.41188421e-04\n",
      "  -8.05277781e-03 -6.82883312e-03]\n",
      " [ 9.29676296e-01 -9.67442415e-02  5.06287832e-02 ... -1.55347660e-02\n",
      "  -1.09861577e-02 -3.44745349e-03]\n",
      " [ 9.28088228e-01 -1.02934185e-01  5.98288545e-02 ... -2.60653446e-02\n",
      "  -2.25315897e-02  9.46957382e-03]\n",
      " ...\n",
      " [ 8.42166732e-01  3.09011440e-01  1.90171066e-01 ... -3.49012074e-02\n",
      "   3.68743710e-03 -1.44759079e-02]\n",
      " [ 8.36926421e-01  3.09991095e-01  1.88881687e-01 ... -4.97899055e-02\n",
      "   2.50082387e-03 -6.46275876e-03]\n",
      " [ 8.30329750e-01  3.18890266e-01  1.83496822e-01 ... -4.80590157e-02\n",
      "  -7.60365360e-03  7.53711981e-03]]\n",
      "7\n",
      "[[ 9.28306007e-01 -9.00656771e-02  4.37697997e-02 ...  2.41188421e-04\n",
      "  -8.05277781e-03 -8.07847295e-04]\n",
      " [ 9.29676296e-01 -9.67442415e-02  5.06287832e-02 ... -1.55347660e-02\n",
      "  -1.09861577e-02 -1.72704950e-02]\n",
      " [ 9.28088228e-01 -1.02934185e-01  5.98288545e-02 ... -2.60653446e-02\n",
      "  -2.25315897e-02 -8.47530401e-03]\n",
      " ...\n",
      " [ 8.42166732e-01  3.09011440e-01  1.90171066e-01 ... -3.49012074e-02\n",
      "   3.68743710e-03 -8.51566244e-03]\n",
      " [ 8.36926421e-01  3.09991095e-01  1.88881687e-01 ... -4.97899055e-02\n",
      "   2.50082387e-03 -1.69487416e-04]\n",
      " [ 8.30329750e-01  3.18890266e-01  1.83496822e-01 ... -4.80590157e-02\n",
      "  -7.60365360e-03  6.49181173e-03]]\n",
      "8\n",
      "[[ 9.28306007e-01 -9.00656771e-02  4.37697997e-02 ...  2.41188421e-04\n",
      "  -8.05277781e-03  1.40991655e-03]\n",
      " [ 9.29676296e-01 -9.67442415e-02  5.06287832e-02 ... -1.55347660e-02\n",
      "  -1.09861577e-02  8.63772224e-04]\n",
      " [ 9.28088228e-01 -1.02934185e-01  5.98288545e-02 ... -2.60653446e-02\n",
      "  -2.25315897e-02 -3.72106666e-03]\n",
      " ...\n",
      " [ 8.42166732e-01  3.09011440e-01  1.90171066e-01 ... -3.49012074e-02\n",
      "   3.68743710e-03  2.94643413e-04]\n",
      " [ 8.36926421e-01  3.09991095e-01  1.88881687e-01 ... -4.97899055e-02\n",
      "   2.50082387e-03 -2.06808607e-04]\n",
      " [ 8.30329750e-01  3.18890266e-01  1.83496822e-01 ... -4.80590157e-02\n",
      "  -7.60365360e-03  1.22815315e-04]]\n",
      "9\n",
      "[[ 9.28306007e-01 -9.00656771e-02  4.37697997e-02 ...  2.41188421e-04\n",
      "  -8.05277781e-03  1.82838984e-02]\n",
      " [ 9.29676296e-01 -9.67442415e-02  5.06287832e-02 ... -1.55347660e-02\n",
      "  -1.09861577e-02  1.03594968e-02]\n",
      " [ 9.28088228e-01 -1.02934185e-01  5.98288545e-02 ... -2.60653446e-02\n",
      "  -2.25315897e-02 -1.63936316e-03]\n",
      " ...\n",
      " [ 8.42166732e-01  3.09011440e-01  1.90171066e-01 ... -3.49012074e-02\n",
      "   3.68743710e-03  3.21868176e-02]\n",
      " [ 8.36926421e-01  3.09991095e-01  1.88881687e-01 ... -4.97899055e-02\n",
      "   2.50082387e-03  2.04920585e-02]\n",
      " [ 8.30329750e-01  3.18890266e-01  1.83496822e-01 ... -4.80590157e-02\n",
      "  -7.60365360e-03  1.98293700e-02]]\n",
      "10\n",
      "[[ 9.28306007e-01 -9.00656771e-02  4.37697997e-02 ...  2.41188421e-04\n",
      "  -8.05277781e-03 -2.74723050e-03]\n",
      " [ 9.29676296e-01 -9.67442415e-02  5.06287832e-02 ... -1.55347660e-02\n",
      "  -1.09861577e-02 -1.18397442e-02]\n",
      " [ 9.28088228e-01 -1.02934185e-01  5.98288545e-02 ... -2.60653446e-02\n",
      "  -2.25315897e-02 -7.05461913e-03]\n",
      " ...\n",
      " [ 8.42166732e-01  3.09011440e-01  1.90171066e-01 ... -3.49012074e-02\n",
      "   3.68743710e-03 -1.33973502e-02]\n",
      " [ 8.36926421e-01  3.09991095e-01  1.88881687e-01 ... -4.97899055e-02\n",
      "   2.50082387e-03 -1.60524352e-02]\n",
      " [ 8.30329750e-01  3.18890266e-01  1.83496822e-01 ... -4.80590157e-02\n",
      "  -7.60365360e-03 -1.66710059e-02]]\n",
      "11\n",
      "[[ 9.28306007e-01 -9.00656771e-02  4.37697997e-02 ...  2.41188421e-04\n",
      "  -8.05277781e-03 -4.30723553e-03]\n",
      " [ 9.29676296e-01 -9.67442415e-02  5.06287832e-02 ... -1.55347660e-02\n",
      "  -1.09861577e-02  9.31041807e-04]\n",
      " [ 9.28088228e-01 -1.02934185e-01  5.98288545e-02 ... -2.60653446e-02\n",
      "  -2.25315897e-02  6.78451398e-03]\n",
      " ...\n",
      " [ 8.42166732e-01  3.09011440e-01  1.90171066e-01 ... -3.49012074e-02\n",
      "   3.68743710e-03  3.67473900e-03]\n",
      " [ 8.36926421e-01  3.09991095e-01  1.88881687e-01 ... -4.97899055e-02\n",
      "   2.50082387e-03  7.68967888e-03]\n",
      " [ 8.30329750e-01  3.18890266e-01  1.83496822e-01 ... -4.80590157e-02\n",
      "  -7.60365360e-03 -2.26012630e-03]]\n",
      "12\n",
      "[[ 9.28306007e-01 -9.00656771e-02  4.37697997e-02 ...  2.41188421e-04\n",
      "  -8.05277781e-03 -1.63044199e-03]\n",
      " [ 9.29676296e-01 -9.67442415e-02  5.06287832e-02 ... -1.55347660e-02\n",
      "  -1.09861577e-02  7.55520028e-04]\n",
      " [ 9.28088228e-01 -1.02934185e-01  5.98288545e-02 ... -2.60653446e-02\n",
      "  -2.25315897e-02  6.20666189e-03]\n",
      " ...\n",
      " [ 8.42166732e-01  3.09011440e-01  1.90171066e-01 ... -3.49012074e-02\n",
      "   3.68743710e-03 -1.17474564e-03]\n",
      " [ 8.36926421e-01  3.09991095e-01  1.88881687e-01 ... -4.97899055e-02\n",
      "   2.50082387e-03  2.34051397e-03]\n",
      " [ 8.30329750e-01  3.18890266e-01  1.83496822e-01 ... -4.80590157e-02\n",
      "  -7.60365360e-03 -8.05746136e-04]]\n",
      "13\n",
      "[[ 9.28306007e-01 -9.00656771e-02  4.37697997e-02 ...  2.41188421e-04\n",
      "  -8.05277781e-03 -2.40105850e-03]\n",
      " [ 9.29676296e-01 -9.67442415e-02  5.06287832e-02 ... -1.55347660e-02\n",
      "  -1.09861577e-02 -2.26503329e-03]\n",
      " [ 9.28088228e-01 -1.02934185e-01  5.98288545e-02 ... -2.60653446e-02\n",
      "  -2.25315897e-02 -5.22244800e-03]\n",
      " ...\n",
      " [ 8.42166732e-01  3.09011440e-01  1.90171066e-01 ... -3.49012074e-02\n",
      "   3.68743710e-03 -1.63969698e-03]\n",
      " [ 8.36926421e-01  3.09991095e-01  1.88881687e-01 ... -4.97899055e-02\n",
      "   2.50082387e-03 -1.03772391e-03]\n",
      " [ 8.30329750e-01  3.18890266e-01  1.83496822e-01 ... -4.80590157e-02\n",
      "  -7.60365360e-03 -5.42928836e-03]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14\n",
      "[[ 9.28306007e-01 -9.00656771e-02  4.37697997e-02 ...  2.41188421e-04\n",
      "  -8.05277781e-03  8.46544345e-03]\n",
      " [ 9.29676296e-01 -9.67442415e-02  5.06287832e-02 ... -1.55347660e-02\n",
      "  -1.09861577e-02 -6.20717538e-04]\n",
      " [ 9.28088228e-01 -1.02934185e-01  5.98288545e-02 ... -2.60653446e-02\n",
      "  -2.25315897e-02  1.65969072e-03]\n",
      " ...\n",
      " [ 8.42166732e-01  3.09011440e-01  1.90171066e-01 ... -3.49012074e-02\n",
      "   3.68743710e-03  2.19617053e-03]\n",
      " [ 8.36926421e-01  3.09991095e-01  1.88881687e-01 ... -4.97899055e-02\n",
      "   2.50082387e-03  4.69724060e-03]\n",
      " [ 8.30329750e-01  3.18890266e-01  1.83496822e-01 ... -4.80590157e-02\n",
      "  -7.60365360e-03  5.50959437e-04]]\n",
      "15\n",
      "[[ 9.28306007e-01 -9.00656771e-02  4.37697997e-02 ...  2.41188421e-04\n",
      "  -8.05277781e-03 -3.11486013e-03]\n",
      " [ 9.29676296e-01 -9.67442415e-02  5.06287832e-02 ... -1.55347660e-02\n",
      "  -1.09861577e-02  1.01439088e-03]\n",
      " [ 9.28088228e-01 -1.02934185e-01  5.98288545e-02 ... -2.60653446e-02\n",
      "  -2.25315897e-02  1.03587973e-03]\n",
      " ...\n",
      " [ 8.42166732e-01  3.09011440e-01  1.90171066e-01 ... -3.49012074e-02\n",
      "   3.68743710e-03  5.65159743e-04]\n",
      " [ 8.36926421e-01  3.09991095e-01  1.88881687e-01 ... -4.97899055e-02\n",
      "   2.50082387e-03  3.09316950e-03]\n",
      " [ 8.30329750e-01  3.18890266e-01  1.83496822e-01 ... -4.80590157e-02\n",
      "  -7.60365360e-03 -2.92885497e-03]]\n",
      "16\n",
      "[[ 9.28306007e-01 -9.00656771e-02  4.37697997e-02 ...  2.41188421e-04\n",
      "  -8.05277781e-03 -3.04963881e-03]\n",
      " [ 9.29676296e-01 -9.67442415e-02  5.06287832e-02 ... -1.55347660e-02\n",
      "  -1.09861577e-02 -4.42088789e-04]\n",
      " [ 9.28088228e-01 -1.02934185e-01  5.98288545e-02 ... -2.60653446e-02\n",
      "  -2.25315897e-02 -1.19200334e-02]\n",
      " ...\n",
      " [ 8.42166732e-01  3.09011440e-01  1.90171066e-01 ... -3.49012074e-02\n",
      "   3.68743710e-03  5.94906591e-03]\n",
      " [ 8.36926421e-01  3.09991095e-01  1.88881687e-01 ... -4.97899055e-02\n",
      "   2.50082387e-03  1.24002224e-02]\n",
      " [ 8.30329750e-01  3.18890266e-01  1.83496822e-01 ... -4.80590157e-02\n",
      "  -7.60365360e-03  1.15300866e-03]]\n",
      "17\n",
      "[[ 9.28306007e-01 -9.00656771e-02  4.37697997e-02 ...  2.41188421e-04\n",
      "  -8.05277781e-03 -1.05682052e-02]\n",
      " [ 9.29676296e-01 -9.67442415e-02  5.06287832e-02 ... -1.55347660e-02\n",
      "  -1.09861577e-02 -9.15522354e-03]\n",
      " [ 9.28088228e-01 -1.02934185e-01  5.98288545e-02 ... -2.60653446e-02\n",
      "  -2.25315897e-02 -1.31058874e-02]\n",
      " ...\n",
      " [ 8.42166732e-01  3.09011440e-01  1.90171066e-01 ... -3.49012074e-02\n",
      "   3.68743710e-03  2.60825652e-03]\n",
      " [ 8.36926421e-01  3.09991095e-01  1.88881687e-01 ... -4.97899055e-02\n",
      "   2.50082387e-03 -9.51589494e-03]\n",
      " [ 8.30329750e-01  3.18890266e-01  1.83496822e-01 ... -4.80590157e-02\n",
      "  -7.60365360e-03 -1.03586592e-02]]\n",
      "18\n",
      "[[ 9.28306007e-01 -9.00656771e-02  4.37697997e-02 ...  2.41188421e-04\n",
      "  -8.05277781e-03 -1.77148442e-02]\n",
      " [ 9.29676296e-01 -9.67442415e-02  5.06287832e-02 ... -1.55347660e-02\n",
      "  -1.09861577e-02 -7.40006392e-03]\n",
      " [ 9.28088228e-01 -1.02934185e-01  5.98288545e-02 ... -2.60653446e-02\n",
      "  -2.25315897e-02 -2.94992492e-03]\n",
      " ...\n",
      " [ 8.42166732e-01  3.09011440e-01  1.90171066e-01 ... -3.49012074e-02\n",
      "   3.68743710e-03 -1.96187717e-03]\n",
      " [ 8.36926421e-01  3.09991095e-01  1.88881687e-01 ... -4.97899055e-02\n",
      "   2.50082387e-03  2.83969853e-03]\n",
      " [ 8.30329750e-01  3.18890266e-01  1.83496822e-01 ... -4.80590157e-02\n",
      "  -7.60365360e-03  1.07745839e-03]]\n",
      "19\n",
      "[[ 9.28306007e-01 -9.00656771e-02  4.37697997e-02 ...  2.41188421e-04\n",
      "  -8.05277781e-03 -1.02323628e-02]\n",
      " [ 9.29676296e-01 -9.67442415e-02  5.06287832e-02 ... -1.55347660e-02\n",
      "  -1.09861577e-02 -1.01651968e-02]\n",
      " [ 9.28088228e-01 -1.02934185e-01  5.98288545e-02 ... -2.60653446e-02\n",
      "  -2.25315897e-02 -4.59508959e-03]\n",
      " ...\n",
      " [ 8.42166732e-01  3.09011440e-01  1.90171066e-01 ... -3.49012074e-02\n",
      "   3.68743710e-03 -1.32111822e-02]\n",
      " [ 8.36926421e-01  3.09991095e-01  1.88881687e-01 ... -4.97899055e-02\n",
      "   2.50082387e-03 -7.19821607e-03]\n",
      " [ 8.30329750e-01  3.18890266e-01  1.83496822e-01 ... -4.80590157e-02\n",
      "  -7.60365360e-03  5.37091174e-05]]\n",
      "closest [  3  48  14 159  22  22  31  31  39  39  47  47  55  55  58  63  71  70\n",
      "  79  78 231 230  95  95  94  98 110 111 118 118 126 126  79 111 231 158\n",
      " 121 146 159 158 166 167 175  39 181 181 190 190 131 199 206 206 215 214\n",
      " 221 223 231 210 208 375 246 246 255 254 262 263 254 278 278 278 382 287\n",
      " 294 294 296 303 311 311 319 318 323 325 334 334 335 334 231  43 254 254\n",
      " 327 366 374 238 231 381 391 231 399 398 407 231 247 264]\n",
      "closest [  6  55  14  61  22  22  31  31  39  39  47  47  55  55  63  63  71  70\n",
      "  79  78 230 230  95  95  90 102 110 111 118 118 110 126  78 321 158 158\n",
      "  63 164 159 159 166 167 175 278 183 181 191  30 196 199 206 207 215 297\n",
      " 222 223 231 210 210 232 246 246 255 254 263 263  62 271 278 327 382 287\n",
      " 294 294 296 303 311 311 318 262 327 227 334 328 335 343  78 230 254 353\n",
      " 327 366 374 238 231 376 391  87 399 398 407 231 410 230]\n",
      "closest [  7   6  14  14  20  20  31  31  39  39  47  47  55  55 231  63  71  70\n",
      "  79  78  86 230  95  95 359 320 110 111 118 118 126 126 390 119 208 137\n",
      "  63 146 159 158 166 167 175 244 183 155 190 190 134 131 206 206 215 214\n",
      " 221 223 231 231 303 238 246 246 255 254 263 263  38 278 278 278 375 287\n",
      " 294 294 391 303 311 311 319  62 274 312   6  72 335 340  79  43 353 242\n",
      " 121 366 263 231 231 231 391 297 206 398 407  63 247 135]\n",
      "closest [  6   3 262 156  22  22  26  31  39  38  47  40  55  55  62  63  71  70\n",
      "  78  78 230 204  95  95 239  99 110 111 118 118 123 126 159 132 175 108\n",
      " 121 135 187 158 166 161   0   5 179 180   6 146 131 194 206 206 214 215\n",
      " 218 223 231 204 130 231 243 243 255 254 263 263 231 263 278 327 382 287\n",
      " 294 295 296 303 311 311 254 250 327 205 340 335 335 343 238 351 353 268\n",
      " 263 366 374 238 387 376 391 230 302 398 407 406 408 254]\n",
      "closest [  7   7  14 103  21  16  31  31  39 108  46  46  55  55  63  63  71  70\n",
      "  79  79 294 230  94  95 206  99 110 111  32 118 126 126  79 119 158 158\n",
      " 167 164 159 137 166 167 175 306 182 181  51  27 131 199 206 206 214 215\n",
      " 390 223 230 404 204 375 408 241 251 255 262 263 203 302 278 394 388 287\n",
      " 294 294 297 396 311 311 319 262 323 327 387 335 336 343 350 345 355 355\n",
      " 263 366 374 238 287 377 391  63 399 398 407  63 245 318]\n",
      "closest [  7   7  14 159  22  22  31  31  39  39  47  47  55  55  63  63  71  70\n",
      "  79  78 239 230  95  95 311 103 110 111 118 118 126 126  79 231 175 158\n",
      " 121 160 159 158 166 167 175 118 183 183 188 190  87 199 206 207 214 215\n",
      " 221 218 231 210 231 375 246 246 254 254 262 263  61 278 278 278 287 287\n",
      " 294 294 296 303 311 311 318 318 327 227 335 334 335 343 231  43 353 254\n",
      " 365 366 374 231 231 377 391  87 302 398 407 231 246 231]\n",
      "closest [  7   7  14  14  22  22  31  31  39  39  47  47  55  55  63  63  71  70\n",
      "  79  78 239 230  95  95 359  98 110 111 118 118 126 126  79 135 158 158\n",
      " 121 146 159 158 166 167 175 118 183 183   7 190 199 199 206 207 215 215\n",
      " 221 223 231 230 231 231 246 246 255 255 262 263 119 278 278 278 287 287\n",
      " 294 294 297 303 311 311 318 318 323 227 335 334 335 343   5  43 353 353\n",
      " 327 366 374 231 230 377 391  87 399 398 407 231 247 296]\n",
      "closest [  3   3  14  14  22  22  31  31  39  39  47  47  55  55  63  63  71  70\n",
      "  79  78  87 230  95  95 359 103 110 111 118 118 126 126  79 135 158 158\n",
      " 121 146 159 158 166 167 175 118 183 183 188 190  87 199 206 207 215 214\n",
      " 221 223 231 231 231 375 246 246 255 254 262 263 254 278 278 278 287 287\n",
      " 294 294 296 303 311 311 319 318 323 325 335 334 335 343 261  43 254 353\n",
      " 360 366 374 238 231 381 391  87 399 398 407 231 247 296]\n",
      "closest [  5   5  14  15  19  22  30  31  39 123  47  95  55  55  63  63  71  70\n",
      "  79  78 388  87  95  95  90  98 110 111 118 103 110 126 131  70 175 137\n",
      " 306 146 159 158 166 167 175  39 182 181 191  30 196 199 206 358 215 301\n",
      " 218 223 231 262 231 231 246 247 251 254 321 263 254 278 278 275 382 287\n",
      " 294 294 296 303 311 311 319 318 323 227 335 334 335 343   5  43 353 353\n",
      " 124 366 230 231 387 383 391 297 399 398 407 126  63 321]\n",
      "closest [  7   7  14 159  22  22  31  31  39  39  47  47  55  55  63  63  71  70\n",
      "  79  78  87 230  95  95 359 103 110 111 118 118 126 126  78 135 175 158\n",
      " 121 167 159 158 166 167 175  39 183 183   7 190  87 199 206 207 215 215\n",
      " 221 223 231 230 231 231 246 246 255 255 262 263 255 278 278 278 287 287\n",
      " 294 294 296 303 311 311 319 318 327 205 335 334 335 343 231  43 254 353\n",
      " 327 366 374 231 231 377 391 231 399 398 407 231 247 296]\n",
      "closest [  3   7  14  14  22  22  31  31  39  39  47  47  55  55  63  63  71  70\n",
      "  79  78  87 230  94  95 359  98 110 111 118 118 123 126  78 231 142 158\n",
      " 121 164 159 158 166 167 175 172 181 181 187 189  87 199 206 207 215 214\n",
      " 221 218 231 231 231 231 246 246 254 255 262 263 254 278 278 278 287 287\n",
      " 295 294 296 303 311 311 320 318 323 371 335 334 335 343 192  43  61  63\n",
      " 230 366 230 231 231 376 391 297 399 398 407 231 247 321]\n",
      "closest [  7   7  14  14  22  22  26  31  39  32  47  46  55  55  63  63  71  70\n",
      "  79  78 231 230  91  95  57  99 110 111 118 118 110 126 132 231 158 137\n",
      " 126 160 159 158 166 167 175 302 181 181 188 189 131 199 206 207 214 215\n",
      " 221 218 231 231 231 375 246 246 254 255 262 263 271 278 278 278 287 287\n",
      " 294 294 296 303 311 311 319 318 323 371 335 334 335 343 261 345 353 254\n",
      " 366 366 374 238 380 376 391  87 302 398 407 406 408 296]\n",
      "closest [  3   3  14  14  22  22  31  31  39  39  47  47  55  55  63  63  71  70\n",
      "  79  78 231 231  95  95 359 126 110 111 118 118 126 126  79 134 158 158\n",
      " 111 167 159 158 166 167 175 118 182 146   7 146 192 199 206 207 214 230\n",
      " 221 223 231 239 231 375 246 247 255 254 262 263  63 278 278 278 287 287\n",
      " 294 294 296 303 311 311 318 318 323 302 335 334 335 343 261 350 353 355\n",
      " 231 366 374 373 388 377 391 231 399 398 407 231 247 264]\n",
      "closest [  7   7  14  60  22  22  31  31  39  39  46  46  55  55  63  63  71  70\n",
      "  79  78 231 230  95  95 359  99 110 111 118 118 126 126  79 135 156 158\n",
      " 121 146 159 158 166 167 175 118 183 181 191 187  65 199 206 206 215 215\n",
      " 221 223 231 239 231 238 246 246 254 255 231 263  61 278 278 278 382 287\n",
      " 294 294 296 303 311 311 318 318 325 325 335 328 335 343 231 351 255 353\n",
      " 366 366 374 231 377 377 391 231 399 398 407 231 410 264]\n",
      "closest [  7   7  60  63  22  22  31  31  39  39  47  46  55  55  63  63  71  70\n",
      "  79  78 231 231  95  92 359 103 110 111 118 118 175 126  78 118 175 158\n",
      " 135 160 159 158 166 167 175 142 181 181  51 185 134 199 206 207 215 215\n",
      " 221 218 231 231 231 368 246 240 255 255 231 263  61 302 278 278 287 287\n",
      " 294 294 296 303 311 311 319 318 323 325 335 334 335 343   3 345 353 353\n",
      "  63 366 230 238 381 214 391 231 302 398 407 231 243 296]\n",
      "closest [  7 303  12  12  19  22  30  31  38  38 303 303  55  55  63  63  71  70\n",
      "  78  78 238  87  88 302 359 147 110 111 118 118 110 142  79 119 158 158\n",
      " 134 167 126 158 166 167 175  39 178 155  27 187 156 199 206 207 215 215\n",
      " 387 223 230 210 124 373 246 246 319 255 262 374  63 327 278 327 365 287\n",
      " 294 294 296 303 311 311 318 313 325 325 388 329 335 343 231 345 353 353\n",
      " 339 231 263 230 376 377 391  63 214 218 407 400 410 264]\n",
      "closest [  3   3  14  14  22  22  31  31  39  39  47  40  55  55  63  63  71  70\n",
      "  79  78 231 230  95  95 359 103 110 111 118 118 126 126  79 135 175 158\n",
      " 121 160 159 158 166 167 175 190 183 159 190 146 131 199 206 206 215 214\n",
      " 221 223 231 203 231 368 246 246 255 254 262 263 271 278 278 278 287 287\n",
      " 295 294 296 303 311 311 319 318 323 205 335 334 335 343 350  43 353 255\n",
      " 366 366 374 231 381 381 391 231 399 398 407  46 247 296]\n",
      "closest [  7   7  14  15  22  22  31  31  39  39  47  47  55  55  63  63  71  70\n",
      "  79  78 231 230  95  95 359  98 110 111 118 118 126 126  79 135 158 158\n",
      " 121 160 159 158 166 167 175 118 183 181 188  27 231 199 206 207 215 215\n",
      " 221 223 231 231 231 375 246 246 255 255 262 263 254 278 278 278 287 287\n",
      " 294 294 297 303 311 311 319 318 323 206 335 334 335 343 231  43 353 353\n",
      " 230 366 374 238 230 381 391 231 399 398 407 231 247 231]\n",
      "closest [  6   7  14  61  22  22  31  31  39  39  47  47  55  55  63  63  71  70\n",
      "  79  78 231 230  95  95 359 103 110 111 118 118 126 126  79 135 175 158\n",
      " 121 167 159 158 166 167 175  39 183 183 188 187  87 199 206 207 215 215\n",
      " 221 223 231 210 231 231 246 247 255 254 262 263 254 278 278 278 287 287\n",
      " 294 294 296 303 311 311 319 318 327 302 335 334 335 343 231  43 255 255\n",
      " 366 366 374 231 231 377 391 231 399 398 407 231 247 296]\n",
      "closest [  7   7  14  14  22  22  31  31  39  39  47  47  55  55  63  63  71  70\n",
      "  79  78  86 230  95  95 359 103 110 111 118 118 126 126  79 135 175 158\n",
      " 126 160 159 158 166 167 175 142 183 181 188 190 131 199 206 206 215 215\n",
      " 221 223 231 203 231 375 246 246 255 255 262 263  63 278 278 327 382 287\n",
      " 294 294 297 303 311 311 318 318 325 325 335 334 335 343 351 351 254 353\n",
      " 374 366 374 325 381 381 391 231 399 398 407 406 415 264]\n",
      "Mpca:  416  Mlda:  416  Classification rate:  42.30769230769231 %.\n"
     ]
    }
   ],
   "source": [
    "ensemble_results = get_PCALDA_accuracy(416, 416, random=True, committee_size=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    W = get_Wopt(pca_training_data, lda_training_data, 416, 416, True, 47, 70, committee_size)\n",
    "#     print(\"reached here\")\n",
    "    \n",
    "    training_face_weights = np.matmul(np.transpose(W,(0,2,1)),pca_training_data.T)\n",
    "    testing_face_weights = np.matmul(np.transpose(W,(0,2,1)),pca_testing_data.T)\n",
    "#     print(\"training_face_weights.shape\", training_face_weights.shape)\n",
    "#     print(\"tresting_face_weights.shape\", testing_face_weights.shape)\n",
    "    \n",
    "    result = class_rate_tensor(np.transpose(training_face_weights.real,(0,2,1)), np.transpose(testing_face_weights.real, (0,2,1)))\n",
    "    acc = 100*np.sum(result, axis=-1)/len(result)\n",
    "    print(\"Mpca: \", Mpca, \" Mlda: \", Mlda, \" Classification rate: \", acc, \"%.\")\n",
    "    return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
